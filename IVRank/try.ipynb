{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📡 Fetching full CALL chain for QQQ on 2025-04-16…\n",
      "Fetched 1000 rows @ offset 0 (total=1000)\n",
      "Fetched 1000 rows @ offset 1000 (total=2000)\n",
      "Fetched 1000 rows @ offset 2000 (total=3000)\n",
      "Fetched 1000 rows @ offset 3000 (total=4000)\n",
      "Fetched 1000 rows @ offset 4000 (total=5000)\n",
      "Fetched 1000 rows @ offset 5000 (total=6000)\n",
      "Fetched 1000 rows @ offset 6000 (total=7000)\n",
      "Fetched 1000 rows @ offset 7000 (total=8000)\n",
      "Fetched 1000 rows @ offset 8000 (total=9000)\n",
      "Fetched 1000 rows @ offset 9000 (total=10000)\n",
      "Fetched 1000 rows @ offset 10000 (total=11000)\n",
      "Reached end of data at offset 11000 (status 422).\n",
      "✅ Wrote 11000 contracts to QQQ_chain_2025-04-16.csv\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "fetch_qqq_contracts_chain.py\n",
    "\n",
    "Fetch the full QQQ options chain for CALLs on a given snapshot date\n",
    "using the `/options/contracts` endpoint, compute true DTE from `exp_date`,\n",
    "sort by ascending DTE, and write to CSV. Handles 422/404 as end-of-data.\n",
    "\"\"\"\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import time\n",
    "\n",
    "# ─── CONFIGURATION ─────────────────────────────────────────────────────────────\n",
    "API_TOKEN = \"67fb3d6f50c489.92544905\"       # Your EODHD API token\n",
    "SYMBOL    = \"QQQ\"\n",
    "SNAPSHOT  = \"2025-04-16\"                    # Snapshot date for chain\n",
    "BASE_URL  = \"https://eodhd.com/api/mp/unicornbay/options/contracts\"\n",
    "PAGE_LIMIT= 1000                            # Max per docs\n",
    "PAUSE_SEC = 0.2                             # To respect rate limits (1000 req/min)\n",
    "\n",
    "# ─── FETCH FULL CHAIN VIA /options/contracts ──────────────────────────────────\n",
    "def fetch_contracts_for_date(trade_date):\n",
    "    all_records = []\n",
    "    offset = 0\n",
    "\n",
    "    while True:\n",
    "        params = {\n",
    "            \"api_token\":                   API_TOKEN,\n",
    "            \"filter[underlying_symbol]\":   SYMBOL,\n",
    "            \"filter[date_eq]\":             trade_date,\n",
    "            \"filter[type]\":                \"call\",\n",
    "            \"page[limit]\":                 PAGE_LIMIT,\n",
    "            \"page[offset]\":                offset,\n",
    "            \"sort\":                        \"exp_date\",  # nearest expirations first\n",
    "            \"compact\":                     \"0\",\n",
    "        }\n",
    "        resp = requests.get(BASE_URL, params=params)\n",
    "        if resp.status_code in (422, 404):\n",
    "            print(f\"Reached end of data at offset {offset} (status {resp.status_code}).\")\n",
    "            break\n",
    "        try:\n",
    "            resp.raise_for_status()\n",
    "        except requests.HTTPError:\n",
    "            print(f\"HTTP error @ offset {offset}: {resp.status_code}\", file=sys.stderr)\n",
    "            sys.exit(1)\n",
    "\n",
    "        data = resp.json().get(\"data\", [])\n",
    "        if not data:\n",
    "            break\n",
    "\n",
    "        all_records.extend(data)\n",
    "        print(f\"Fetched {len(data)} rows @ offset {offset} (total={len(all_records)})\")\n",
    "        if len(data) < PAGE_LIMIT:\n",
    "            break\n",
    "\n",
    "        offset += PAGE_LIMIT\n",
    "        time.sleep(PAUSE_SEC)\n",
    "\n",
    "    return all_records\n",
    "\n",
    "# ─── MAIN ──────────────────────────────────────────────────────────────────────\n",
    "def main():\n",
    "    print(f\"📡 Fetching full CALL chain for {SYMBOL} on {SNAPSHOT}…\")\n",
    "    records = fetch_contracts_for_date(SNAPSHOT)\n",
    "    if not records:\n",
    "        print(\"❌ No chain data returned—check API key/date.\", file=sys.stderr)\n",
    "        sys.exit(1)\n",
    "\n",
    "    df = pd.json_normalize(records)\n",
    "    df[\"exp_date\"] = pd.to_datetime(df[\"attributes.exp_date\"], errors=\"coerce\")\n",
    "    df[\"trade_dt\"] = pd.to_datetime(SNAPSHOT)\n",
    "    df[\"dte\"]      = (df[\"exp_date\"] - df[\"trade_dt\"]).dt.days\n",
    "    df[\"dte\"]      = pd.to_numeric(df[\"dte\"], errors=\"coerce\")\n",
    "\n",
    "    df_sorted = df.sort_values(\"dte\")\n",
    "    output = f\"{SYMBOL}_chain_{SNAPSHOT}.csv\"\n",
    "    df_sorted.to_csv(output, index=False)\n",
    "    print(f\"✅ Wrote {len(df_sorted)} contracts to {output}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
