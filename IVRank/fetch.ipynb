{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Fetching all CALL data for QQQ (2024-04-16→2025-04-16)…\n",
      "Fetched 1000 rows @ offset 0 (total=1000)\n",
      "Fetched 1000 rows @ offset 1000 (total=2000)\n",
      "Fetched 1000 rows @ offset 2000 (total=3000)\n",
      "Fetched 1000 rows @ offset 3000 (total=4000)\n",
      "Fetched 1000 rows @ offset 4000 (total=5000)\n",
      "Fetched 1000 rows @ offset 5000 (total=6000)\n",
      "Fetched 1000 rows @ offset 6000 (total=7000)\n",
      "Fetched 1000 rows @ offset 7000 (total=8000)\n",
      "Fetched 1000 rows @ offset 8000 (total=9000)\n",
      "Fetched 1000 rows @ offset 9000 (total=10000)\n",
      "Fetched 1000 rows @ offset 10000 (total=11000)\n",
      "✅ Wrote 11000 records to QQQ_calls_sorted_by_dte.csv\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "fetch_qqq_calls_sorted.py\n",
    "\n",
    "Fetch all end‑of‑day CALL option data for QQQ from EODHD,\n",
    "ordering expirations ascending so you get nearest‐term contracts first,\n",
    "and write all contract attributes to CSV sorted by DTE ascending.\n",
    "\"\"\"\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "import sys\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# ─── CONFIGURATION ─────────────────────────────────────────────────────────────\n",
    "API_TOKEN   = \"67fb3d6f50c489.92544905\"  # Your EODHD API token\n",
    "SYMBOL      = \"QQQ\"\n",
    "END_DATE    = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "START_DATE  = (datetime.today() - timedelta(days=365)).strftime(\"%Y-%m-%d\")\n",
    "BASE_URL    = \"https://eodhd.com/api/mp/unicornbay/options/eod\"\n",
    "PAGE_LIMIT  = 1000                        # Per EODHD docs\n",
    "PAUSE_SEC   = 0.6                         # To respect rate limits (1000 req/min)\n",
    "\n",
    "# ─── FETCH ALL CALL OPTIONS WITH ASCENDING EXPIRY ──────────────────────────────\n",
    "def fetch_all_calls():\n",
    "    all_records = []\n",
    "    offset = 0\n",
    "\n",
    "    while True:\n",
    "        params = {\n",
    "            \"api_token\":                 API_TOKEN,\n",
    "            \"filter[underlying_symbol]\": SYMBOL,\n",
    "            \"filter[tradetime_from]\":    START_DATE,\n",
    "            \"filter[tradetime_to]\":      END_DATE,\n",
    "            \"filter[type]\":              \"call\",\n",
    "            \"page[limit]\":               PAGE_LIMIT,\n",
    "            \"page[offset]\":              offset,\n",
    "            \"sort\":                      \"exp_date\",  # ascending by expiration date\n",
    "            \"compact\":                   \"0\",\n",
    "        }\n",
    "        resp = requests.get(BASE_URL, params=params)\n",
    "        # stop on 422/404 to avoid errors at high offsets\n",
    "        if resp.status_code in (422, 404):\n",
    "            break\n",
    "        resp.raise_for_status()\n",
    "\n",
    "        data = resp.json().get(\"data\", [])\n",
    "        if not data:\n",
    "            break\n",
    "\n",
    "        all_records.extend(data)\n",
    "        print(f\"Fetched {len(data)} rows @ offset {offset} (total={len(all_records)})\")\n",
    "        if len(data) < PAGE_LIMIT:\n",
    "            break\n",
    "\n",
    "        offset += PAGE_LIMIT\n",
    "        time.sleep(PAUSE_SEC)\n",
    "\n",
    "    return all_records\n",
    "\n",
    "# ─── MAIN ──────────────────────────────────────────────────────────────────────\n",
    "def main():\n",
    "    print(f\"🔍 Fetching all CALL data for {SYMBOL} ({START_DATE}→{END_DATE})…\")\n",
    "    records = fetch_all_calls()\n",
    "    if not records:\n",
    "        print(\"❌ No records fetched — check API token or date range.\", file=sys.stderr)\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Flatten JSON into DataFrame\n",
    "    df = pd.json_normalize(records)\n",
    "\n",
    "    # Convert DTE to numeric and sort ascending\n",
    "    df[\"dte\"] = pd.to_numeric(df[\"attributes.dte\"], errors=\"coerce\")\n",
    "    df_sorted = df.sort_values(\"dte\")\n",
    "\n",
    "    # Write to CSV\n",
    "    output_file = f\"{SYMBOL}_calls_sorted_by_dte.csv\"\n",
    "    df_sorted.to_csv(output_file, index=False)\n",
    "    print(f\"✅ Wrote {len(df_sorted)} records to {output_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
