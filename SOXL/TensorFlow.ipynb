{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (8, 5, 22, 49)\n",
      "y shape: (8,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"advanced_options_model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"advanced_options_model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ seq_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">49</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_5              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,200</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">23,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ seq_input (\u001b[38;5;33mInputLayer\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m49\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_5              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │         \u001b[38;5;34m3,200\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │        \u001b[38;5;34m23,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m51\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">26,251</span> (102.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m26,251\u001b[0m (102.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">26,251</span> (102.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m26,251\u001b[0m (102.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 1.2239 - val_loss: 0.2946\n",
      "Epoch 2/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 1.0961 - val_loss: 0.3538\n",
      "Epoch 3/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.9799 - val_loss: 0.4570\n",
      "Epoch 4/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.8728 - val_loss: 0.6053\n",
      "Epoch 5/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.7728 - val_loss: 0.8003\n",
      "Epoch 6/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.6786 - val_loss: 1.0459\n",
      "Epoch 7/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.5916 - val_loss: 1.3423\n",
      "Epoch 8/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.5120 - val_loss: 1.6869\n",
      "Epoch 9/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.4402 - val_loss: 2.0757\n",
      "Epoch 10/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.3781 - val_loss: 2.5007\n",
      "Epoch 11/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.3277 - val_loss: 2.9475\n",
      "Epoch 12/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.2912 - val_loss: 3.3928\n",
      "Epoch 13/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.2696 - val_loss: 3.8034\n",
      "Epoch 14/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.2618 - val_loss: 4.1391\n",
      "Epoch 15/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.2637 - val_loss: 4.3647\n",
      "Epoch 16/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.2693 - val_loss: 4.4597\n",
      "Epoch 17/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.2726 - val_loss: 4.4231\n",
      "Epoch 18/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.2696 - val_loss: 4.2713\n",
      "Epoch 19/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.2593 - val_loss: 4.0302\n",
      "Epoch 20/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.2430 - val_loss: 3.7305\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 600ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  True_Close_next  Predicted_Close_next\n",
      "0  2025-03-31            15.95             16.798996\n",
      "1  2025-04-01            16.26             14.844572\n",
      "2  2025-04-02            11.41             12.732158\n",
      "3  2025-04-03             8.73              9.318368\n",
      "4  2025-04-04             9.15              7.552315\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, TimeDistributed, GlobalAveragePooling1D, Masking\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# -----------------------------------\n",
    "# 1. Load and Prepare the Data\n",
    "# -----------------------------------\n",
    "\n",
    "# Load the engineered dataset and ensure dates are parsed\n",
    "df = pd.read_csv('merged_data_engineered.csv')\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Sort the dataframe by Date (oldest first)\n",
    "df = df.sort_values('Date').reset_index(drop=True)\n",
    "\n",
    "# If there are categorical columns that are not numeric, encode them.\n",
    "# For example, encode \"type\" (if present) as: call -> 1, put -> 0.\n",
    "if df['type'].dtype == object:\n",
    "    df['type'] = df['type'].map({'call': 1, 'put': 0})\n",
    "\n",
    "# Define the list of feature columns. Here we include every column except \"Date\".\n",
    "# (The \"Close/Last\" column will be used as a feature for the current day, but the target is the next day's value.)\n",
    "feature_cols = [\n",
    "    'Close/Last', 'ohlcv_volume', 'Open', 'High', 'Low', 'type', 'strike',\n",
    "    'open', 'high', 'low', 'last', 'last_size', 'change', 'pctchange', 'previous',\n",
    "    'bid', 'bid_size', 'ask', 'ask_size', 'moneyness', 'option_volume',\n",
    "    'volume_change', 'volume_pctchange', 'open_interest', 'open_interest_change',\n",
    "    'open_interest_pctchange', 'volatility', 'volatility_change', 'volatility_pctchange',\n",
    "    'theoretical', 'delta', 'gamma', 'theta', 'vega', 'rho', 'vol_oi_ratio', 'dte',\n",
    "    'midpoint', 'daily_return', 'sma_5', 'sma_10', 'ema_12', 'ema_26',\n",
    "    'macd', 'macd_signal', 'rsi_14', 'atr_14', 'intraday_range_pct',\n",
    "    'options_to_ohlcv_volume_ratio'\n",
    "]\n",
    "\n",
    "# Drop rows with missing feature values in these columns\n",
    "df = df.dropna(subset=feature_cols)\n",
    "\n",
    "# Group by each unique day so that each day’s options data is retained\n",
    "grouped = df.groupby('Date')\n",
    "\n",
    "# Create lists to hold each day's options data and corresponding date\n",
    "days = []\n",
    "dates = []\n",
    "for date, group in grouped:\n",
    "    # Extract the feature values from the group\n",
    "    day_data = group[feature_cols].values.astype(np.float32)\n",
    "    days.append(day_data)\n",
    "    dates.append(date)\n",
    "\n",
    "# Sort the days by date\n",
    "sorted_indices = np.argsort(dates)\n",
    "days = [days[i] for i in sorted_indices]\n",
    "dates = [dates[i] for i in sorted_indices]\n",
    "\n",
    "# Create target values:\n",
    "# For each day, we want to predict the next day’s close.\n",
    "# We assume that the day's \"Close/Last\" is the same for all rows of that day,\n",
    "# so we take the first row's \"Close/Last\" from the next day.\n",
    "targets = []\n",
    "for i in range(len(days) - 1):\n",
    "    next_day_close = days[i+1][0, feature_cols.index('Close/Last')]\n",
    "    targets.append(next_day_close)\n",
    "    \n",
    "# Remove the last day as it has no following day's close to predict\n",
    "days = days[:-1]\n",
    "dates = dates[:-1]\n",
    "targets = np.array(targets)\n",
    "\n",
    "# Since each day can have a variable number of options records,\n",
    "# we pad the data so that every day has the same shape.\n",
    "max_options = max(day.shape[0] for day in days)\n",
    "# days_padded will have shape (n_days, max_options, n_features)\n",
    "days_padded = pad_sequences(days, maxlen=max_options, dtype='float32', \n",
    "                            padding='post', truncating='post')\n",
    "\n",
    "# -----------------------------------\n",
    "# 2. Create Lookback Sequences\n",
    "# -----------------------------------\n",
    "# Use a lookback window so that each training sample is\n",
    "# built from the previous \"lookback\" days' options data.\n",
    "lookback = 5  # Example: use the previous 5 days\n",
    "\n",
    "X, y, X_dates = [], [], []\n",
    "for i in range(lookback, len(targets)):\n",
    "    # X: sequence of day data from the past \"lookback\" days\n",
    "    X.append(days_padded[i-lookback:i])\n",
    "    # y: the target for the current day (next day close)\n",
    "    y.append(targets[i])\n",
    "    X_dates.append(dates[i])\n",
    "    \n",
    "X = np.array(X)  # shape: (n_samples, lookback, max_options, n_features)\n",
    "y = np.array(y)\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)\n",
    "\n",
    "# -----------------------------------\n",
    "# 3. Scale the Data\n",
    "# -----------------------------------\n",
    "# Scale X: reshape to 2D, scale, then reshape back.\n",
    "n_samples, lb, max_opts, n_features = X.shape\n",
    "X_reshaped = X.reshape(-1, n_features)\n",
    "scaler_X = StandardScaler()\n",
    "X_scaled_reshaped = scaler_X.fit_transform(X_reshaped)\n",
    "X_scaled = X_scaled_reshaped.reshape(n_samples, lb, max_opts, n_features)\n",
    "\n",
    "# Scale y:\n",
    "scaler_y = StandardScaler()\n",
    "y_scaled = scaler_y.fit_transform(y.reshape(-1, 1)).flatten()\n",
    "\n",
    "# -----------------------------------\n",
    "# 4. Build the LSTM RNN Model with L2 Regularization\n",
    "# -----------------------------------\n",
    "# Use L2 regularization factor (adjust as needed)\n",
    "l2_reg = 0.001\n",
    "\n",
    "# Number of features remains the same.\n",
    "n_features = len(feature_cols)\n",
    "\n",
    "# Sub-model to process a single day’s options data.\n",
    "# Input shape: (max_options, n_features)\n",
    "option_input = Input(shape=(max_options, n_features), name='option_input')\n",
    "# Mask padded rows (assumed to be zeros)\n",
    "masked = Masking(mask_value=0.0)(option_input)\n",
    "# Process each option row individually with a TimeDistributed Dense layer including L2 regularization.\n",
    "option_dense = TimeDistributed(Dense(64, activation='relu', kernel_regularizer=l2(l2_reg)))(masked)\n",
    "# Aggregate the processed rows into a fixed-length vector using global average pooling.\n",
    "day_embedding = GlobalAveragePooling1D()(option_dense)\n",
    "# Create the day-level model that outputs a daily embedding.\n",
    "day_model = Model(inputs=option_input, outputs=day_embedding, name='day_model')\n",
    "\n",
    "# Define the sequence model.\n",
    "# Input: sequence of days with shape (lookback, max_options, n_features)\n",
    "seq_input = Input(shape=(lookback, max_options, n_features), name='seq_input')\n",
    "# Apply the day_model to each day in the sequence using TimeDistributed.\n",
    "day_embeddings = TimeDistributed(day_model)(seq_input)  # shape: (lookback, 64)\n",
    "# Feed the sequence of day embeddings into an LSTM layer to capture temporal dynamics.\n",
    "lstm_out = LSTM(50, activation='tanh')(day_embeddings)\n",
    "# Final Dense layer to predict the next day’s closing price with L2 regularization.\n",
    "output = Dense(1, kernel_regularizer=l2(l2_reg))(lstm_out)\n",
    "\n",
    "# Build and compile the complete model.\n",
    "model = Model(inputs=seq_input, outputs=output, name='advanced_options_model')\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.summary()\n",
    "\n",
    "# -----------------------------------\n",
    "# 5. Train the Model\n",
    "# -----------------------------------\n",
    "# Train using the scaled data.\n",
    "history = model.fit(X_scaled, y_scaled, epochs=20, batch_size=16, validation_split=0.2)\n",
    "\n",
    "# -----------------------------------\n",
    "# 6. Evaluate and Save Predictions\n",
    "# -----------------------------------\n",
    "# Generate predictions on the entire dataset.\n",
    "predictions_scaled = model.predict(X_scaled)\n",
    "# Invert target scaling\n",
    "predictions = scaler_y.inverse_transform(predictions_scaled)\n",
    "results_df = pd.DataFrame({\n",
    "    'Date': [d.strftime('%Y-%m-%d') for d in X_dates],\n",
    "    'True_Close_next': y.flatten(),\n",
    "    'Predicted_Close_next': predictions.flatten()\n",
    "})\n",
    "print(results_df.head())\n",
    "\n",
    "# Save the trained model and the predictions for later analysis.\n",
    "model.save('advanced_options_close_predictor.h5')\n",
    "results_df.to_csv('advanced_expanding_window_predictions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (8, 5, 22, 49)\n",
      "y shape: (8,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"advanced_options_model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"advanced_options_model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ seq_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">49</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_13             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,200</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">23,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ seq_input (\u001b[38;5;33mInputLayer\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m49\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_13             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │         \u001b[38;5;34m3,200\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_6 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │        \u001b[38;5;34m23,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m51\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">26,251</span> (102.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m26,251\u001b[0m (102.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">26,251</span> (102.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m26,251\u001b[0m (102.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 1.4281 - val_loss: 0.4024\n",
      "Epoch 2/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 1.2173 - val_loss: 0.3957\n",
      "Epoch 3/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 1.0636 - val_loss: 0.4218\n",
      "Epoch 4/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.9430 - val_loss: 0.4898\n",
      "Epoch 5/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.8379 - val_loss: 0.6140\n",
      "Epoch 6/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.7391 - val_loss: 0.8100\n",
      "Epoch 7/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.6436 - val_loss: 1.0905\n",
      "Epoch 8/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.5525 - val_loss: 1.4632\n",
      "Epoch 9/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.4697 - val_loss: 1.9266\n",
      "Epoch 10/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.3994 - val_loss: 2.4650\n",
      "Epoch 11/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3454 - val_loss: 3.0451\n",
      "Epoch 12/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.3085 - val_loss: 3.6155\n",
      "Epoch 13/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.2869 - val_loss: 4.1144\n",
      "Epoch 14/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.2770 - val_loss: 4.4894\n",
      "Epoch 15/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.2750 - val_loss: 4.7164\n",
      "Epoch 16/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.2787 - val_loss: 4.7984\n",
      "Epoch 17/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.2847 - val_loss: 4.7607\n",
      "Epoch 18/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.2874 - val_loss: 4.6351\n",
      "Epoch 19/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.2817 - val_loss: 4.4468\n",
      "Epoch 20/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.2671 - val_loss: 4.2115\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464ms/step\n",
      "In-sample predictions:\n",
      "         Date  True_Close_next  Predicted_Close_next\n",
      "0  2025-03-31            15.95             16.835896\n",
      "1  2025-04-01            16.26             15.033982\n",
      "2  2025-04-02            11.41             13.124949\n",
      "3  2025-04-03             8.73              9.762660\n",
      "4  2025-04-04             9.15              7.800424\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 728ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mason\\AppData\\Local\\Temp\\ipykernel_34952\\2304559750.py:166: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_preds_df = pd.concat([results_df, future_df], ignore_index=True)\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All predictions from 2025-03-31 to 2025-04-10:\n",
      "         Date  True_Close_next  Predicted_Close_next\n",
      "0  2025-03-31            15.95             16.835896\n",
      "1  2025-04-01            16.26             15.033982\n",
      "2  2025-04-02            11.41             13.124949\n",
      "3  2025-04-03             8.73              9.762660\n",
      "4  2025-04-04             9.15              7.800424\n",
      "5  2025-04-07             8.25              6.850358\n",
      "6  2025-04-08            12.77              5.565059\n",
      "7  2025-04-09             9.63              4.924136\n",
      "8  2025-04-10              NaN              4.396750\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, TimeDistributed, GlobalAveragePooling1D, Masking\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# -----------------------------------\n",
    "# 1. Load and Prepare the Data\n",
    "# -----------------------------------\n",
    "\n",
    "df = pd.read_csv('merged_data_engineered.csv')\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df = df.sort_values('Date').reset_index(drop=True)\n",
    "\n",
    "# Encode 'type' as a binary variable if needed.\n",
    "if df['type'].dtype == object:\n",
    "    df['type'] = df['type'].map({'call': 1, 'put': 0})\n",
    "\n",
    "feature_cols = [\n",
    "    'Close/Last', 'ohlcv_volume', 'Open', 'High', 'Low', 'type', 'strike',\n",
    "    'open', 'high', 'low', 'last', 'last_size', 'change', 'pctchange', 'previous',\n",
    "    'bid', 'bid_size', 'ask', 'ask_size', 'moneyness', 'option_volume',\n",
    "    'volume_change', 'volume_pctchange', 'open_interest', 'open_interest_change',\n",
    "    'open_interest_pctchange', 'volatility', 'volatility_change', 'volatility_pctchange',\n",
    "    'theoretical', 'delta', 'gamma', 'theta', 'vega', 'rho', 'vol_oi_ratio', 'dte',\n",
    "    'midpoint', 'daily_return', 'sma_5', 'sma_10', 'ema_12', 'ema_26',\n",
    "    'macd', 'macd_signal', 'rsi_14', 'atr_14', 'intraday_range_pct',\n",
    "    'options_to_ohlcv_volume_ratio'\n",
    "]\n",
    "\n",
    "df = df.dropna(subset=feature_cols)\n",
    "\n",
    "# Group by Date so that each day's options data is retained.\n",
    "grouped = df.groupby('Date')\n",
    "days, dates = [], []\n",
    "for date, group in grouped:\n",
    "    day_data = group[feature_cols].values.astype(np.float32)\n",
    "    days.append(day_data)\n",
    "    dates.append(date)\n",
    "\n",
    "# Ensure days are sorted by date.\n",
    "sorted_idx = np.argsort(dates)\n",
    "days = [days[i] for i in sorted_idx]\n",
    "dates = [dates[i] for i in sorted_idx]\n",
    "\n",
    "# Create target values: for each day, predict the next day's Close/Last.\n",
    "targets = []\n",
    "for i in range(len(days) - 1):\n",
    "    next_day_close = days[i+1][0, feature_cols.index('Close/Last')]\n",
    "    targets.append(next_day_close)\n",
    "\n",
    "# Remove the last day (no target)\n",
    "days = days[:-1]\n",
    "dates = dates[:-1]\n",
    "targets = np.array(targets)\n",
    "\n",
    "# Pad each day’s options data so every day has shape (max_options, n_features)\n",
    "max_options = max(day.shape[0] for day in days)\n",
    "days_padded = pad_sequences(days, maxlen=max_options, dtype='float32', padding='post', truncating='post')\n",
    "\n",
    "# -----------------------------------\n",
    "# 2. Create Lookback Sequences\n",
    "# -----------------------------------\n",
    "# Here lookback=5 means each sample uses the previous 5 days.\n",
    "lookback = 5\n",
    "X, y, X_dates = [], [], []\n",
    "for i in range(lookback, len(targets)):\n",
    "    X.append(days_padded[i-lookback:i])\n",
    "    y.append(targets[i])\n",
    "    X_dates.append(dates[i])\n",
    "    \n",
    "X = np.array(X)  # shape: (n_samples, lookback, max_options, n_features)\n",
    "y = np.array(y)\n",
    "\n",
    "print(\"X shape:\", X.shape)  # e.g., (n_samples, 5, max_options, n_features)\n",
    "print(\"y shape:\", y.shape)\n",
    "\n",
    "# -----------------------------------\n",
    "# 3. Scale the Data\n",
    "# -----------------------------------\n",
    "n_samples, lb, max_opts, n_features = X.shape\n",
    "X_reshaped = X.reshape(-1, n_features)\n",
    "scaler_X = StandardScaler()\n",
    "X_scaled_reshaped = scaler_X.fit_transform(X_reshaped)\n",
    "X_scaled = X_scaled_reshaped.reshape(n_samples, lb, max_opts, n_features)\n",
    "\n",
    "scaler_y = StandardScaler()\n",
    "y_scaled = scaler_y.fit_transform(y.reshape(-1, 1)).flatten()\n",
    "\n",
    "# -----------------------------------\n",
    "# 4. Build the LSTM RNN Model with L2 Regularization\n",
    "# -----------------------------------\n",
    "l2_reg = 0.001\n",
    "\n",
    "# Sub-model for a single day's options data.\n",
    "option_input = Input(shape=(max_options, n_features), name='option_input')\n",
    "masked = Masking(mask_value=0.0)(option_input)\n",
    "option_dense = TimeDistributed(Dense(64, activation='relu', kernel_regularizer=l2(l2_reg)))(masked)\n",
    "day_embedding = GlobalAveragePooling1D()(option_dense)\n",
    "day_model = Model(inputs=option_input, outputs=day_embedding, name='day_model')\n",
    "\n",
    "seq_input = Input(shape=(lookback, max_options, n_features), name='seq_input')\n",
    "day_embeddings = TimeDistributed(day_model)(seq_input)  # shape: (lookback, 64)\n",
    "lstm_out = LSTM(50, activation='tanh')(day_embeddings)\n",
    "output = Dense(1, kernel_regularizer=l2(l2_reg))(lstm_out)\n",
    "\n",
    "model = Model(inputs=seq_input, outputs=output, name='advanced_options_model')\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.summary()\n",
    "\n",
    "# -----------------------------------\n",
    "# 5. Train the Model\n",
    "# -----------------------------------\n",
    "history = model.fit(X_scaled, y_scaled, epochs=20, batch_size=16, validation_split=0.2)\n",
    "\n",
    "# -----------------------------------\n",
    "# 6. Generate Predictions for Every Date\n",
    "# -----------------------------------\n",
    "# Our current in-sample predictions correspond to dates in X_dates.\n",
    "# These predictions use a full lookback window. Note that with lookback=5,\n",
    "# the earliest prediction we get is for the 6th date in our data.\n",
    "# To obtain a prediction for every date from 2025-03-05 to 2025-04-10\n",
    "# (assuming 2025-03-04 is the first date), you could:\n",
    "#   - either reduce lookback to 1 so each day (except the first) is predicted,\n",
    "#   - or accept that with lookback=5 predictions only start when a full window is available.\n",
    "#\n",
    "# Here, we show how to get the in-sample predictions and then add one out-of-sample forecast\n",
    "# for the day after the last day in our dataset (2025-04-11).\n",
    "\n",
    "# In-sample predictions:\n",
    "preds_scaled = model.predict(X_scaled)\n",
    "preds = scaler_y.inverse_transform(preds_scaled)\n",
    "\n",
    "# Assemble a DataFrame for in-sample predicted dates (these correspond to X_dates).\n",
    "pred_dates = [d.strftime('%Y-%m-%d') for d in X_dates]\n",
    "results_df = pd.DataFrame({\n",
    "    'Date': pred_dates,\n",
    "    'True_Close_next': y.flatten(),\n",
    "    'Predicted_Close_next': preds.flatten()\n",
    "})\n",
    "\n",
    "print(\"In-sample predictions:\")\n",
    "print(results_df.head())\n",
    "\n",
    "# For an out-of-sample forecast for 2025-04-11:\n",
    "# Use the last available lookback window from the padded data.\n",
    "last_window = days_padded[-lookback:]  # shape: (lookback, max_options, n_features)\n",
    "# Scale this window using the same scaler_X.\n",
    "last_window_scaled = scaler_X.transform(last_window.reshape(-1, n_features)).reshape(lookback, max_opts, n_features)\n",
    "# Expand dims to match model input: (1, lookback, max_options, n_features)\n",
    "last_window_scaled = np.expand_dims(last_window_scaled, axis=0)\n",
    "future_pred_scaled = model.predict(last_window_scaled)\n",
    "future_pred = scaler_y.inverse_transform(future_pred_scaled)[0, 0]\n",
    "future_date = (dates[-1] + pd.Timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "\n",
    "# Append the out-of-sample forecast to the results.\n",
    "future_df = pd.DataFrame({\n",
    "    'Date': [future_date],\n",
    "    'True_Close_next': [np.nan],   # No true value available yet.\n",
    "    'Predicted_Close_next': [future_pred]\n",
    "})\n",
    "\n",
    "all_preds_df = pd.concat([results_df, future_df], ignore_index=True)\n",
    "\n",
    "print(\"\\nAll predictions from {} to {}:\".format(pred_dates[0], future_date))\n",
    "print(all_preds_df)\n",
    "\n",
    "# Save the predictions.\n",
    "all_preds_df.to_csv('advanced_expanding_window_predictions.csv', index=False)\n",
    "model.save('advanced_options_close_predictor.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
